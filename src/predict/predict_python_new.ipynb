{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Machine Learning to predict the probability of needing Post-Mastectomy Radiotherapy\n",
    "Author: Yifu (Charles) Chen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import modules ###\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import re\n",
    "import copy\n",
    "# Machine Learning Modules for Random Forest, Logistic Regression, and XGBoost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "# Logging\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup no print limits and etc.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "class bcolors:\n",
    "    # Helper class to print in terminal with colors\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    NORMAL = '\\033[0m'\n",
    "    \n",
    "def setup_logging():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.NOTSET)\n",
    "    logging.basicConfig(\n",
    "            format=\"%(asctime)s - %(levelname)s - %(message)s \\n\",\n",
    "            datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "            handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler(f\"{os.getcwd()}/log.txt\")],\n",
    "            level=logging.NOTSET\n",
    "        )\n",
    "    return logger\n",
    "\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept the largest DF\n",
      "07/26/2022 14:24:06 - INFO - 9_PRE-1.0spars-expert-ML-imputed89cols \n",
      "\n",
      "07/26/2022 14:24:06 - INFO - E_POS-1.0spars-expert-ML-imputed132cols \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Directory of DataFrames\n",
    "dir_to_df = \"/Users/yifu/PycharmProjects/Radiotherapy-Prediction/data/output/2022-07-13-133052_without_imputation/DataFrames/subset_dataframes\"\n",
    "\n",
    "# Path to log file\n",
    "log_path = os.path.join(dir_to_df, \"log.txt\")\n",
    "use_full_cols = True\n",
    "# Create a new log file from scratch, regardless if one exists\n",
    "with open(log_path, \"w\") as log_file:\n",
    "    log_file.write(\"\")\n",
    "\n",
    "def print_and_log(*args):\n",
    "    # Helper function to print and log\n",
    "    # Can handle writing DataFrame to log file\n",
    "    logger.info(*args)\n",
    "    with open(log_path, \"a\") as log_file:\n",
    "        if type(args[0]) == pd.DataFrame:\n",
    "            log_file.write(args[0].to_string() + \"\\n\")\n",
    "        else:\n",
    "            log_file.write(\"|| \".join([str(a) for a in args]) + \"\\n\")\n",
    "\n",
    "    \n",
    "# Assume all files in directory are CSV DataFrame files\n",
    "paths_to_df = glob.glob(os.path.join(dir_to_df, \"*.csv\"))\n",
    "\n",
    "# Read each DataFrame file\n",
    "dfs = OrderedDict()\n",
    "for i, path in enumerate(paths_to_df):\n",
    "    if use_full_cols and \"1.0\" not in path:\n",
    "        continue\n",
    "    df_name = path.replace(dir_to_df, \"\")\n",
    "    df_name = df_name.replace(\"/\", \"\").replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(path)\n",
    "    if i == len(paths_to_df) - 1:\n",
    "        print(\"Kept the largest DF\")\n",
    "        df_all = df.copy()\n",
    "        # dfs[\"df_all\"] = df\n",
    "    # Drop \"PRE_record_id\" column, if it exists\n",
    "    if \"PRE_record_id\" in df.columns:\n",
    "        df = df.drop(columns=[\"PRE_record_id\"], axis=1)\n",
    "    dfs[df_name] = df\n",
    "# Sorted the dict by path name\n",
    "dfs = OrderedDict(sorted(dfs.items()))\n",
    "\n",
    "for k in dfs.keys():\n",
    "    print_and_log(k)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['POS_metastasis'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000008?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m df_name, df \u001b[39min\u001b[39;00m dfs\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000008?line=6'>7</a>\u001b[0m     \u001b[39m# Standardize all columns except the target column target_column\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000008?line=7'>8</a>\u001b[0m     df_std \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000008?line=8'>9</a>\u001b[0m     df_std\u001b[39m.\u001b[39;49mdrop([target_column], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000008?line=9'>10</a>\u001b[0m     df_std \u001b[39m=\u001b[39m (df_std \u001b[39m-\u001b[39m df_std\u001b[39m.\u001b[39mmean()) \u001b[39m/\u001b[39m df_std\u001b[39m.\u001b[39mstd()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000008?line=10'>11</a>\u001b[0m     df_std \u001b[39m=\u001b[39m df_std\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   4955\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   4956\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   4957\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   4958\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   4959\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   4960\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   4961\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   4962\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4269\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['POS_metastasis'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Standardize the data by removing the mean and scaling to unit variance\n",
    "# The target variable is named target_column\n",
    "\n",
    "dfs_std = OrderedDict()\n",
    "\n",
    "for df_name, df in dfs.items():\n",
    "    # Standardize all columns except the target column target_column\n",
    "    df_std = df.copy()\n",
    "    df_std.drop([target_column], axis=1, inplace=True)\n",
    "    df_std = (df_std - df_std.mean()) / df_std.std()\n",
    "    df_std = df_std.copy()\n",
    "    # Concatenate the target column back\n",
    "    df_std[target_column] = df[target_column]\n",
    "    # Convert the target column to binary\n",
    "    df_std[target_column] = df_std[target_column] > 0\n",
    "    dfs_std[df_name] = df_std\n",
    "\n",
    "len(dfs_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Machine Learning Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def impute_missing_value(df_unimputed, target_column, max_iter):\n",
    "    \"\"\"Given a DataFrame with missing values, impute them using IterativeImputer.\n",
    "    Leave the target_column as is.\n",
    "\n",
    "    Args:\n",
    "        df_unimputed (DataFrame): DataFrame with missing values.\n",
    "    \"\"\"\n",
    "    imp = IterativeImputer(max_iter=max_iter, random_state=0, verbose=0)\n",
    "    X = df_unimputed.drop(target_column, axis=1)\n",
    "    y = df_unimputed[target_column]\n",
    "    X_imputed = imp.fit_transform(X)\n",
    "    df_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "    df_imputed[target_column] = y\n",
    "    return df_imputed\n",
    "\n",
    "def standardize_data(df_unstandardized, target_column):\n",
    "    \"\"\"Standardize the data using sklearn.\n",
    "\n",
    "    Args:\n",
    "        df_unstandardized (DataFrame): DataFrame with missing values.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X = df_unstandardized.drop(target_column, axis=1)\n",
    "    y = df_unstandardized[target_column]\n",
    "    X_standardized = scaler.fit_transform(X)\n",
    "    df_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "    df_standardized[target_column] = y\n",
    "    # Drop columns with all NaNs\n",
    "    df_standardized.dropna(axis=1, how=\"all\", inplace=True)\n",
    "    return df_standardized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/26/2022 14:23:03 - INFO - Processing 9_PRE-1.0spars-expert-ML-imputed89cols... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:980: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:1005: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3... Fold 4... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/26/2022 14:23:44 - INFO -                                Dataset               Model Avg Accuracy SE Accuracy Avg AUC  SE AUC  Avg F1   SE F1\n",
      "9_PRE-1.0spars-expert-ML-imputed89cols Logistic Regression       0.7069      0.0115  0.7657  0.0126   0.615  0.0174\n",
      "9_PRE-1.0spars-expert-ML-imputed89cols       Random Forest       0.7245      0.0162  0.7712  0.0181  0.6208  0.0275\n",
      "9_PRE-1.0spars-expert-ML-imputed89cols             XGBoost       0.7008      0.0135  0.7599  0.0176  0.6048  0.0236 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - \n",
      "----------The 1/3 (28 out of 84) most important features for Logistic Regression:---------- \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_systhe___radiation: 1.1317 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_num_closest_margins_trans: 0.8031 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_bra_cup_size: 0.6574 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_max_size_composite: 0.6182 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_int_mammary_lymphade_pet: 0.4823 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_lymph_node_max_size_mm: 0.4384 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_susp_LN_prsnt_composite: 0.4158 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_ax_surg___sln_biopsy: 0.4107 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_ax_surg___no_ax_surg: 0.3856 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_axillary_lymph_node_palpab: 0.3773 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_his_subtype___dcis: 0.3674 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_abnormal_lymph: 0.3517 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_metastatic_carcinoma_on_ax: 0.3459 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_img_size: 0.3433 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_her_status: 0.3075 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_stge: 0.3047 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_dximg___ultrasound: 0.2809 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_systhe___no_systhe: 0.2786 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_dximg___mammography: 0.2768 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_er_status: 0.2744 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_age_at_surg: 0.2627 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_bmi: 0.2619 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_high_grade_fdg_foci_presen: 0.2543 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_lymphovascular_invasion0: 0.246 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_his_subtype___idc: 0.2381 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_grade: 0.2341 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_systhe___chemo: 0.2224 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_axillary_lymph_node_max_si: 0.2183 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - \n",
      "----------The 1/3 (28 out of 84) most important features for Random Forest:---------- \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_high_grade_fdg_foci_presen: 0.0491 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_sln_met_nomogram_prob: 0.0351 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_axillary_lymph_node_max_si: 0.0344 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_lymph_node_max_size_mm: 0.0337 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_num_closest_margins_trans: 0.0336 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_max_size_composite: 0.032 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_distance_from_closest_marg: 0.031 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_img_size: 0.0306 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_margin_status: 0.0303 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_size_mm: 0.0295 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_size_of_the_largest_foci_c: 0.0288 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_height_cm: 0.028 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_bra_cup_size: 0.028 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_weight_kg: 0.0278 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_stge: 0.0276 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_location: 0.0274 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_bmi: 0.0272 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_bi_rads_score: 0.0269 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_lymph_node_max_size_mm0: 0.0269 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_dob: 0.0247 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_age_at_dx: 0.0244 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_location_trans: 0.0243 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_age_at_surg: 0.0241 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_his_subtype___dcis: 0.0207 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_susp_LN_prsnt_composite: 0.0182 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_axillary_lymph_node_core_b: 0.0172 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_susp_LN_size_composite: 0.0156 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_his_subtype___idc: 0.0151 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - \n",
      "----------The 1/3 (28 out of 84) most important features for XGBoost:---------- \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_susp_LN_prsnt_composite: 0.2343 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_imaging_and_biopsy_concord: 0.0547 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_systhe___radiation: 0.0485 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_his_subtype___dcis: 0.0405 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_metastatic_carcinoma_on_ax: 0.0379 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_ax_surg___ax_ln_dissect: 0.037 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_lymphovascular_invasion0: 0.0333 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_axillary_lymph_node_core_b: 0.027 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_his_subtype___idc: 0.0211 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_palpability: 0.0184 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_susp_LN_size_composite: 0.018 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_max_size_composite: 0.0152 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_surg_indicat_prim___primary_tx: 0.0149 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_her_status: 0.0148 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_high_grade_fdg_foci_presen: 0.0133 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_men_status: 0.0132 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_max_enhancement_measurment: 0.013 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_age_at_dx: 0.0117 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_stge: 0.0113 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_dximg___mammography: 0.0106 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_ax_surg___no_ax_surg: 0.0106 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_sln_met_nomogram_prob: 0.0104 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_age_at_surg: 0.0097 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_lymph_node_max_size_mm: 0.0094 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_pr_status: 0.0093 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_er_status: 0.009 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_num_closest_margins_trans: 0.0089 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - PRE_tumor_grade: 0.0087 \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - ====================================================================================================================================================== \n",
      "\n",
      "07/26/2022 14:23:44 - INFO - Processing E_POS-1.0spars-expert-ML-imputed132cols... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:980: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/yifu/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:1005: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 174>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=170'>171</a>\u001b[0m         plot_dict[df_name] \u001b[39m=\u001b[39m print_df\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=171'>172</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m plot_dict, all_top_features\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=173'>174</a>\u001b[0m plot_dict, all_top_features \u001b[39m=\u001b[39m generate_feature_scores_and_plot(dfs_std, target_column)\n",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb Cell 13'\u001b[0m in \u001b[0;36mgenerate_feature_scores_and_plot\u001b[0;34m(dfs_std, target_col)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=150'>151</a>\u001b[0m \u001b[39mfor\u001b[39;00m df_name, df \u001b[39min\u001b[39;00m dfs_std\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=151'>152</a>\u001b[0m     print_and_log(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mdf_name\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=152'>153</a>\u001b[0m     print_df, feature_scores \u001b[39m=\u001b[39m build_classifiers(df, df_name, num_folds\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, target_col\u001b[39m=\u001b[39;49mtarget_col)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=153'>154</a>\u001b[0m     \u001b[39m# print the DataFrame without the index\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=154'>155</a>\u001b[0m     print_and_log(print_df\u001b[39m.\u001b[39mto_string(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb Cell 13'\u001b[0m in \u001b[0;36mbuild_classifiers\u001b[0;34m(df, df_name, num_folds, target_col)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=29'>30</a>\u001b[0m \u001b[39m# # Impute missing values with KNN\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=30'>31</a>\u001b[0m \u001b[39m# from sklearn.impute import KNNImputer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=31'>32</a>\u001b[0m \u001b[39m# imputer = KNNImputer(n_neighbors=5)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=38'>39</a>\u001b[0m \u001b[39m# df_imp[target_col] = df[target_col]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=39'>40</a>\u001b[0m \u001b[39m# df = df_imp.copy()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=40'>41</a>\u001b[0m df \u001b[39m=\u001b[39m standardize_data(df, target_col)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=41'>42</a>\u001b[0m df \u001b[39m=\u001b[39m impute_missing_value(df, target_col, max_iter\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=42'>43</a>\u001b[0m \u001b[39massert\u001b[39;00m df\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39msum() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=44'>45</a>\u001b[0m \u001b[39m# Initialize a dictionary for holding the models for each DataFrame\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000012?line=45'>46</a>\u001b[0m \u001b[39m# Schema: {\"Fold 1\": {\"Model Name\": Model Object, ...}, ...}\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_testing.py:318\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    317\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategory)\n\u001b[0;32m--> 318\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb Cell 12'\u001b[0m in \u001b[0;36mimpute_missing_value\u001b[0;34m(df_unimputed, target_column, max_iter)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000011?line=14'>15</a>\u001b[0m X \u001b[39m=\u001b[39m df_unimputed\u001b[39m.\u001b[39mdrop(target_column, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000011?line=15'>16</a>\u001b[0m y \u001b[39m=\u001b[39m df_unimputed[target_column]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000011?line=16'>17</a>\u001b[0m X_imputed \u001b[39m=\u001b[39m imp\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000011?line=17'>18</a>\u001b[0m df_imputed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(X_imputed, columns\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python_new.ipynb#ch0000011?line=18'>19</a>\u001b[0m df_imputed[target_column] \u001b[39m=\u001b[39m y\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:665\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[39mfor\u001b[39;00m feat_idx \u001b[39min\u001b[39;00m ordered_idx:\n\u001b[1;32m    662\u001b[0m     neighbor_feat_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[1;32m    663\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[1;32m    664\u001b[0m     )\n\u001b[0;32m--> 665\u001b[0m     Xt, estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_impute_one_feature(\n\u001b[1;32m    666\u001b[0m         Xt,\n\u001b[1;32m    667\u001b[0m         mask_missing_values,\n\u001b[1;32m    668\u001b[0m         feat_idx,\n\u001b[1;32m    669\u001b[0m         neighbor_feat_idx,\n\u001b[1;32m    670\u001b[0m         estimator\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    671\u001b[0m         fit_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    672\u001b[0m     )\n\u001b[1;32m    673\u001b[0m     estimator_triplet \u001b[39m=\u001b[39m _ImputerTriplet(\n\u001b[1;32m    674\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[1;32m    675\u001b[0m     )\n\u001b[1;32m    676\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimputation_sequence_\u001b[39m.\u001b[39mappend(estimator_triplet)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:318\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    316\u001b[0m     X_train \u001b[39m=\u001b[39m _safe_indexing(X_filled[:, neighbor_feat_idx], \u001b[39m~\u001b[39mmissing_row_mask)\n\u001b[1;32m    317\u001b[0m     y_train \u001b[39m=\u001b[39m _safe_indexing(X_filled[:, feat_idx], \u001b[39m~\u001b[39mmissing_row_mask)\n\u001b[0;32m--> 318\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m    320\u001b[0m \u001b[39m# if no missing values, don't predict\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39msum(missing_row_mask) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_bayes.py:283\u001b[0m, in \u001b[0;36mBayesianRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    280\u001b[0m coef_old_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    282\u001b[0m XT_y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X\u001b[39m.\u001b[39mT, y)\n\u001b[0;32m--> 283\u001b[0m U, S, Vh \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49msvd(X, full_matrices\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    284\u001b[0m eigen_vals_ \u001b[39m=\u001b[39m S\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39m# Convergence loop of the bayesian ridge regression\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m lwork \u001b[39m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], a1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m    124\u001b[0m                        compute_uv\u001b[39m=\u001b[39mcompute_uv, full_matrices\u001b[39m=\u001b[39mfull_matrices)\n\u001b[1;32m    126\u001b[0m \u001b[39m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m u, s, v, info \u001b[39m=\u001b[39m gesXd(a1, compute_uv\u001b[39m=\u001b[39;49mcompute_uv, lwork\u001b[39m=\u001b[39;49mlwork,\n\u001b[1;32m    128\u001b[0m                       full_matrices\u001b[39m=\u001b[39;49mfull_matrices, overwrite_a\u001b[39m=\u001b[39;49moverwrite_a)\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSVD did not converge\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize a dictionary for holding the models for each DataFrame\n",
    "# Schema: {\"DataFrame Name\": {\"Model Name\": Model Object, ...}, ...}\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "\n",
    "all_models = defaultdict(dict)\n",
    "\n",
    "# The print_df contains the dataframe, model, and the average CV accuracy, AUC, and the top 6 features and their scores\n",
    "# metrics_df_columns = [\"Dataset\", \"Model\", \"Avg CV Accuracy\", \"Avg CV AUC\", \"Avg CV F1\", \"Feature_1\", \"Score_1\", \"Feature_2\", \"Score_2\", \n",
    "#                     \"Feature_3\", \"Score_3\", \"Feature_4\", \"Score_4\", \"Feature_5\", \"Score_5\", \"Feature_6\", \"Score_6\"]\n",
    "\n",
    "metrics_df_columns = [\"Dataset\", \"Model\"] + list(itertools.chain(*[[\"Avg \" + m, \"SE \" + m] for m in [\"Accuracy\", \"AUC\", \"F1\"]]))\n",
    "\n",
    "def build_classifiers(df: pd.DataFrame, df_name: str, num_folds: int, target_col: str) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    For each DataFrame, build the following classifiers:\n",
    "        Logistic Regression\n",
    "        Random Forest\n",
    "        XGBoost\n",
    "    Args:\n",
    "        df (pd.DataFrame): the DataFrame to build the classifiers for\n",
    "        df_name (str): the name of the DataFrame\n",
    "        num_folds (int): the number of folds to use for cross-validation\n",
    "        target_col (str): the name of the target column\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # # Impute missing values with KNN\n",
    "    # from sklearn.impute import KNNImputer\n",
    "    # imputer = KNNImputer(n_neighbors=5)\n",
    "    # # Drop columns that are all NaN, also drop the target column\n",
    "    # df_drop_na = df.dropna(axis=1, how=\"all\")\n",
    "    # df_drop_na = df_drop_na.drop(columns=[target_col])\n",
    "    # # Impute the missing values\n",
    "    # df_imp = pd.DataFrame(imputer.fit_transform(df_drop_na), columns=df_drop_na.columns)\n",
    "    # # Put the target back\n",
    "    # df_imp[target_col] = df[target_col]\n",
    "    # df = df_imp.copy()\n",
    "    df = standardize_data(df, target_col)\n",
    "    df = impute_missing_value(df, target_col, max_iter=20)\n",
    "    assert df.isnull().sum().sum() == 0\n",
    "\n",
    "    # Initialize a dictionary for holding the models for each DataFrame\n",
    "    # Schema: {\"Fold 1\": {\"Model Name\": Model Object, ...}, ...}\n",
    "    models = defaultdict(dict)  \n",
    "    performance = defaultdict(dict)\n",
    "    # Train each model using 5-fold cross-validation, repeated 10 times to get error bars\n",
    "    # for i in range(num_cvs):\n",
    "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=1)\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(df, df[target_col])):\n",
    "        fold = fold + 1\n",
    "        print(\"Fold {}\".format(fold), end=\"... \" if fold < num_folds else \"\\n\")\n",
    "        # Split the DataFrame into training and validation sets\n",
    "        df_train, df_val = df.iloc[train_index], df.iloc[test_index]\n",
    "        # Build the classifiers\n",
    "        models[fold] = {\"Logistic Regression\": LogisticRegression(),\n",
    "                        \"Random Forest\": RandomForestClassifier(),\n",
    "                        \"XGBoost\": XGBClassifier()\n",
    "                        }\n",
    "        for model_name, model in models[fold].items():\n",
    "            # Train each model on the target column POS_did_the_patient_receive_pm\n",
    "            # X (all variables for training), Y (target)\n",
    "            model.fit(\n",
    "                df_train.drop([target_col], axis=1),\n",
    "                df_train[target_col]\n",
    "                )\n",
    "            # Predict the validation set\n",
    "            y_pred = model.predict(\n",
    "                df_val.drop([target_col], axis=1)\n",
    "            )\n",
    "            # Calculate the accuracy of the model\n",
    "            accuracy = np.mean(y_pred == df_val[target_col])\n",
    "            # Calcuilate the F1\n",
    "            F1 = f1_score(y_true=df_val[target_col], y_pred=y_pred)\n",
    "            # Predict the probability of the validation set\n",
    "            y_pred_proba = model.predict_proba(df_val.drop([target_col], axis=1))[:, 1]\n",
    "            # Calculate the AUC of the model\n",
    "            auc = metrics.roc_auc_score(df_val[target_col], y_pred_proba)\n",
    "            if model_name != \"Logistic Regression\":\n",
    "                # Get the features for the model\n",
    "                feature_importances = pd.Series(model.feature_importances_, index=df_train.drop([target_col], axis=1).columns)\n",
    "            else:\n",
    "                # The features for the Logistic Regression model are the coefficients\n",
    "                # Take absolute value of the coefficients\n",
    "                feature_importances = pd.Series(np.abs(model.coef_[0]), index=df_train.drop([target_col], axis=1).columns)\n",
    "            # Store the accuracy, AUC, and features for the model\n",
    "            performance[model_name][fold] = {\"accuracy\": accuracy, \"auc\": auc, \"F1\": F1, \"top_features\": feature_importances}\n",
    "    \n",
    "    # Consolidate the top features for each model\n",
    "    # Schema: {\"Model Name\": {\"Feature_1\": Score_1, ...}, ...}\n",
    "    feature_scores = defaultdict(lambda: defaultdict(float))\n",
    "    for model_name, fold in performance.items():\n",
    "        for fold_num, fold_performance in fold.items():\n",
    "            # Extract feature name and importance score\n",
    "            for feature_name, score in fold_performance[\"top_features\"].items():\n",
    "                feature_scores[model_name][feature_name] += score\n",
    "        # Divide the feature importance scores by the number of folds\n",
    "        for feature_name, score in feature_scores[model_name].items():\n",
    "            feature_scores[model_name][feature_name] /= len(fold)\n",
    "            # Round to 4 decimal places\n",
    "            feature_scores[model_name][feature_name] = round(feature_scores[model_name][feature_name], 4)\n",
    "    \n",
    "    # Print the performance of each model, including averaged across folds\n",
    "    # DataFrame for printing results in a nice format\n",
    "    # Columns: Dataset, Model, Avg CV Accuracy, SE Accuracy, Avg CV AUC, SE AUC, Avg CV F1, SE F1\n",
    "    print_df = pd.DataFrame(columns=metrics_df_columns)\n",
    "    for model_name, fold in performance.items():\n",
    "        accuracy = round(np.mean([fold[fold_num][\"accuracy\"] for fold_num in fold.keys()]), 4)\n",
    "        auc = round(np.mean([fold[fold_num][\"auc\"] for fold_num in fold.keys()]), 4)\n",
    "        F1 = round(np.mean([fold[fold_num][\"F1\"] for fold_num in fold.keys()]), 4)\n",
    "        accuracy_se = round(np.std([fold[fold_num][\"accuracy\"] for fold_num in fold.keys()]) / np.sqrt(len(fold)), 4)\n",
    "        auc_se = round(np.std([fold[fold_num][\"auc\"] for fold_num in fold.keys()]) / np.sqrt(len(fold)), 4)\n",
    "        F1_se = round(np.std([fold[fold_num][\"F1\"] for fold_num in fold.keys()]) / np.sqrt(len(fold)), 4)\n",
    "        curr_df = pd.DataFrame(\n",
    "                    [\n",
    "                        [df_name, model_name, accuracy, accuracy_se, auc, auc_se, F1, F1_se]\n",
    "                    ],\n",
    "                    columns=metrics_df_columns\n",
    "                )\n",
    "        print_df = pd.concat(\n",
    "            [\n",
    "                print_df,\n",
    "                curr_df\n",
    "            ],\n",
    "            axis=0\n",
    "        )\n",
    "    # Sort feature scores, using OrderedDict\n",
    "    for model_name, model_feature_scores in feature_scores.items():\n",
    "        feature_scores[model_name] = OrderedDict(sorted(model_feature_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    return print_df, feature_scores\n",
    "\n",
    "def generate_feature_scores_and_plot(dfs_std, target_col):\n",
    "    \"\"\"Generate feature scores and plots for each data subset.\n",
    "\n",
    "    Args:\n",
    "        dfs_std: a dictionary with standardized dataframes for each data subset\n",
    "\n",
    "    Returns:\n",
    "        plot_dict, all_top_features: a dictionary with plots for each data subset, and a dictionary with all top features for each model\n",
    "    \"\"\"\n",
    "    # Build the classifiers for each DataFrame\n",
    "    print_df = pd.DataFrame(columns=metrics_df_columns)\n",
    "    # Create a dictionary for holding the DataFrames for plotting\n",
    "    plot_dict = OrderedDict()\n",
    "    # Create a dictionary for holding all the feature scores across datasets and models\n",
    "    # Schema: {\"Dataset1\": {\"Model1\": {\"Feature_1\": Score_1, ...}, ...}, ...}\n",
    "    all_top_features = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "    for df_name, df in dfs_std.items():\n",
    "        print_and_log(f\"Processing {df_name}...\")\n",
    "        print_df, feature_scores = build_classifiers(df, df_name, num_folds=10, target_col=target_col)\n",
    "        # print the DataFrame without the index\n",
    "        print_and_log(print_df.to_string(index=False))\n",
    "        model_names = feature_scores.keys()\n",
    "        for model in model_names:\n",
    "            top_features = sorted(feature_scores[model].items(), key=lambda x: x[1], reverse=True)[:]\n",
    "            print_and_log(\n",
    "                \"\\n\" + \"-\" * 10 + \n",
    "                f\"The 1/3 ({len(top_features)//3} out of {len(top_features)}) \"\n",
    "                f\"most important features for {model}:\" + \"-\" * 10\n",
    "            )\n",
    "            for i, (feat, score) in enumerate(top_features):\n",
    "                all_top_features[df_name][model][feat] = score\n",
    "                # If the feature is in the top 1/3, print it\n",
    "                if i < len(top_features) / 3:\n",
    "                    print_and_log(f\"{feat}: {score}\")\n",
    "        print_and_log(\"=\"*150)\n",
    "        # Add the DataFrame to the dictionary for plotting later\n",
    "        plot_dict[df_name] = print_df\n",
    "    return plot_dict, all_top_features\n",
    "\n",
    "plot_dict, all_top_features = generate_feature_scores_and_plot(dfs_std, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plot_dir = os.path.join(dir_to_df, \"plots\")\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import plotting libraries for machine learning experiments\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Retrive the saved DataFrames, and plot the results\n",
    "# Plot the results for each DataFrame on a single plot\n",
    "# Reset plot parameters\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "for use_broken_axis in [False, True]:\n",
    "    for metric_name in [\"Accuracy\", \"AUC\", \"F1\"]:\n",
    "        y_data = []\n",
    "        errors = []\n",
    "        x_data = []\n",
    "        # Retrieve the performance for each model\n",
    "        for df_name, print_df in plot_dict.items():\n",
    "            # Iterate through the models of the DataFrame\n",
    "            for i, row in print_df.iterrows():\n",
    "                # If the model is the metric, add it to the list\n",
    "                model_name = row[\"Model\"]\n",
    "                # Use regular expression to retrieve the metric and its standard error\n",
    "                metric = row[\"Avg \" + metric_name]\n",
    "                error = row[\"SE \" + metric_name]\n",
    "                df_name = row[\"Dataset\"]\n",
    "                df_name = df_name.replace(\"/\", \"\").replace(\".csv\", \"\")\n",
    "                x_data.append(metric)\n",
    "                y_data.append(df_name + \" - \" + model_name)\n",
    "                errors.append(error)\n",
    "        # Create the plot\n",
    "        # The plot has spaces between the bars\n",
    "        plt.figure(figsize=(30, 16))\n",
    "        # Plot the gridlines\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        # The color of the bar should alternate between 3 colors\n",
    "        colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]\n",
    "        # Make bars\n",
    "        plt.barh(y_data, x_data, xerr=errors, color=colors, align=\"center\", alpha=0.7)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.xticks(fontsize=18)\n",
    "        # Align the y-tick texts to the left\n",
    "        ax = plt.gca()\n",
    "        # for tick in ax.yaxis.get_majorticklabels():\n",
    "        #     tick.set_horizontalalignment(\"left\")\n",
    "        # Set the labels on top of the bars\n",
    "        for i, v in enumerate(x_data):\n",
    "            plt.text(v + 0.05, y_data[i], str(v), color=\"black\", fontsize=18)\n",
    "        plt.gca().invert_yaxis()\n",
    "        if use_broken_axis:\n",
    "            # Set the range of the x-axis to be between the min - 0.1 and 1\n",
    "            axis_start = min(x_data) - 0.1\n",
    "            plt.xlim(axis_start, 1)\n",
    "\n",
    "        plt.xlabel(metric_name, fontsize=20)\n",
    "        plt.ylabel(\"Model\")\n",
    "        plt.title(f\"{metric_name} by Model\", fontsize=40)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if use_broken_axis:\n",
    "            # Save the plot\n",
    "            plt_name = f\"{metric_name}_br_axis.png\"\n",
    "        else:\n",
    "            plt_name = f\"{metric_name}_full_axis.png\"\n",
    "        plt.savefig(os.path.join(plot_dir, plt_name))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# For each dataset in all_top_features, build a DataFrame with the top features\n",
    "# The features for each model is ranked by their score\n",
    "# The most important features shared by all models are sorted to the top\n",
    "# Create a dictionary for holding the feature scores per dataset\n",
    "# Schema: {\"Dataset1\": {\"Model1\": {\"Feature_1\": score_1, ...}, ...}, ...}\n",
    "def tabularize_feature_ranks(all_top_features, model_names, merged_df_prefixes, top_k_percent=10, do_print=True):\n",
    "    \"\"\"Given a dictionary of top features, tabulate the feature ranks for each model\n",
    "\n",
    "    Args:\n",
    "        all_top_features (_type_): A dictionary of top features\n",
    "        model_names (list, optional): Models for the merged table. Defaults to [\"Random Forest\"].\n",
    "        merged_df_prefixes (list, optional): Prefixes for the merged dataset names, e.g., [\"0\", \"1\", ...]\n",
    "        top_k_percent (int, optional): The top k percent of features to be counted in the final table. Defaults to 40.\n",
    "        do_print (bool, optional): Whether to print the table. Defaults to True.\n",
    "\n",
    "    \"\"\"\n",
    "    # Keep only the datasets that startswith prefixes in merged_df_prefixes\n",
    "    # Create a copy of all_top_features\n",
    "    all_top_features = copy.deepcopy(all_top_features)\n",
    "    for df_name in list(all_top_features.keys()):\n",
    "        if not any([df_name.startswith(prefix) for prefix in merged_df_prefixes]):\n",
    "            del all_top_features[df_name]\n",
    "    \n",
    "    result_df_dict = OrderedDict()\n",
    "    # Columns: Dataset1 Score, Dataset2 Score, ...\n",
    "    # Rows: Feature1, Feature2, ...\n",
    "    # We currently only consider the Random Forest model\n",
    "    for dataset, model_dict in all_top_features.items():\n",
    "        if do_print:\n",
    "            print_and_log(\"-\"*50)\n",
    "            print_and_log(f\"Processing {dataset}...\")\n",
    "            # Print the number of features for this dataset\n",
    "            print_and_log(f\"Number of features: {len(model_dict['Random Forest'])}\")\n",
    "        LR_features = model_dict[\"Logistic Regression\"]\n",
    "        RF_features = model_dict[\"Random Forest\"]\n",
    "        XGB_features = model_dict[\"XGBoost\"]\n",
    "        # Sort the features by their scores\n",
    "        sorted_LR_features = sorted(LR_features.items(), key=lambda x: x[1], reverse=True)\n",
    "        sorted_RF_features = sorted(RF_features.items(), key=lambda x: x[1], reverse=True)\n",
    "        sorted_XGB_features = sorted(XGB_features.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Convert each score into a rank\n",
    "        rank_LR_features = {feat: i+1 for i, (feat, score) in enumerate(sorted_LR_features)}\n",
    "        rank_RF_features = {feat: i+1 for i, (feat, score) in enumerate(sorted_RF_features)}\n",
    "        rank_XGB_features = {feat: i+1 for i, (feat, score) in enumerate(sorted_XGB_features)}\n",
    "        # Assert all the features are present in the sorted features dictionary\n",
    "        assert set(rank_LR_features.keys()) == set(rank_RF_features.keys()) == set(rank_XGB_features.keys())\n",
    "        # Create a DataFrame with all the features\n",
    "        df = pd.DataFrame({\"Features\": list(rank_LR_features.keys())})\n",
    "        # Calculate the feature scores for each model\n",
    "        # Add the ranks of RF to the DataFrame\n",
    "        df[\"RF_rank\"] = df[\"Features\"].map(rank_RF_features)\n",
    "        # Add the ranks of LR to the DataFrame\n",
    "        df[\"LR_rank\"] = df[\"Features\"].map(rank_LR_features)\n",
    "        # Add the ranks of XGB to the DataFrame\n",
    "        df[\"XGB_rank\"] = df[\"Features\"].map(rank_XGB_features)\n",
    "        # Add the raw scores of RF to the DataFrame\n",
    "        df[\"RF_score\"] = df[\"Features\"].map(RF_features)\n",
    "        # Add the raw scores of LR to the DataFrame\n",
    "        df[\"LR_score\"] = df[\"Features\"].map(LR_features)\n",
    "        # Add the raw scores of XGB to the DataFrame\n",
    "        df[\"XGB_score\"] = df[\"Features\"].map(XGB_features)\n",
    "        # Add a column corresponding to the overall ranking using Rank Product Statistic (geometric mean of the ranks)\n",
    "        df[\"Rank_Product^(1/3)\"] = (df[\"RF_rank\"] * df[\"LR_rank\"] * df[\"XGB_rank\"]) ** (1/3)\n",
    "        # Sort the DataFrame by the ranks of the features\n",
    "        df = df.sort_values(by=\"RF_rank\")\n",
    "        df_rank_product = df.sort_values(by=\"Rank_Product^(1/3)\")\n",
    "        # Reset the index\n",
    "        df = df.reset_index(drop=True)\n",
    "        # Add Rank_Product_Rank column, where the rank is the index of the row in df_rank_product\n",
    "        product_rank_map = {feat: i+1 for i, feat in enumerate(df_rank_product[\"Features\"])}\n",
    "        df[\"Rank_Product_Rank\"] =  df[\"Features\"].map(product_rank_map)\n",
    "        \n",
    "        # Keep only the top 1/3 of features (the most important features)\n",
    "        # df = df.iloc[:len(df)//3]\n",
    "        # Round all the entries to 2 decimal places\n",
    "        df = df.round(2)\n",
    "        result_df_dict[dataset] = df\n",
    "        # Print the DataFrame, ignoring the index\n",
    "        if do_print:\n",
    "            print_and_log(df.to_string(index=False))\n",
    "    \n",
    "    # # Keep only the datasets that startswith prefixes in merged_df_prefixes\n",
    "    # result_df_dict = {k: v for k, v in result_df_dict.items() if k.startswith(tuple(merged_df_prefixes))}\n",
    "    \n",
    "    # Get all the features from the feature importance \n",
    "    all_features = set()\n",
    "    for dataset, df in result_df_dict.items():\n",
    "        all_features.update(df[\"Features\"].values)\n",
    "\n",
    "\n",
    "    # Merge the DataFrames for each dataset\n",
    "    # The rows are the features, the columns are the datasets\n",
    "    # The values are the Random Forest and Logistic Regression scores of the features in each dataset\n",
    "    merged_df = pd.DataFrame({\"Features\": list(all_features)})\n",
    "    # Merge feature scores\n",
    "    for dataset_name, df in result_df_dict.items():\n",
    "        dataset_name = dataset_name.replace(\"expert\", \"\").replace(\"imputed\", \"\")\n",
    "        dataset_name = re.sub(\"-{2,}\", \"-\", dataset_name)\n",
    "        # Keep only the columns RF_score and LR_score\n",
    "        for model_name in model_names:\n",
    "            col_name = model_name + \"_\" + dataset_name\n",
    "            feat_to_score_dict = {feat: df[df[\"Features\"] == feat][model_name + \"_score\"].values[0] for feat in df[\"Features\"]}\n",
    "            mean_feature_score = np.mean(list(feat_to_score_dict.values()))\n",
    "            for i, row in merged_df.iterrows():\n",
    "                feat = row[\"Features\"]\n",
    "                if feat in feat_to_score_dict:\n",
    "                    merged_df.loc[i, col_name] = feat_to_score_dict[feat]\n",
    "                else:\n",
    "                    merged_df.loc[i, col_name] = np.nan\n",
    "    # Create a column that counts the frequency of the feature score being among the top features\n",
    "    # For each col in rf_score_cols, and each feature, calculate the frequency of the feature score being among the top K% in this col\n",
    "    top_k_freq_dict = defaultdict(lambda: defaultdict(int))\n",
    "    # Schema: {model_name: {feature: int}}\n",
    "    for dataset_name, df in result_df_dict.items():\n",
    "        df_sorted = df.sort_values(by=\"RF_rank\")\n",
    "        dataset_name = dataset_name.replace(\"expert\", \"\").replace(\"imputed\", \"\")\n",
    "        dataset_name = re.sub(\"-{2,}\", \"-\", dataset_name)\n",
    "        for model_name in model_names:\n",
    "            col_name = model_name + \"_\" + dataset_name\n",
    "            for i, row in merged_df.iterrows():\n",
    "                feat = row[\"Features\"]\n",
    "                feat_score = row[col_name]\n",
    "                is_top_k = 0\n",
    "                if feat_score in df_sorted.iloc[:max(1, int(len(df)*top_k_percent)//100)][model_name+\"_score\"].values:\n",
    "                    is_top_k = 1\n",
    "                top_k_freq_dict[model_name][feat] += is_top_k\n",
    "                # if feat == \"PRE_age_at_dx\" and is_top_k:\n",
    "                #     print(f\"age_at_dx score: {feat_score} in top K of {dataset_name} {model_name}\")\n",
    "                # raise ValueError(\"Fix this problem, not sure why LR isn't counted correctly\")\n",
    "    \n",
    "    # Insert Top_K%_Freq columns after \"Features\" column\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        merged_df.insert(\n",
    "            i+1, model_name+ f\"_Top_{top_k_percent}%_Freq\",\n",
    "            merged_df[\"Features\"].map(top_k_freq_dict[model_name])\n",
    "            )\n",
    "\n",
    "    # Insert _Top_Probability columns\n",
    "    # Where the value is the probability it's top-K% vs the number of times the feature occurred in dataset\n",
    "    num_feature_occurred = defaultdict(int)\n",
    "    for df_name, model_dict in all_top_features.items():\n",
    "        for model, feat_dict in model_dict.items():\n",
    "            for feat in feat_dict.keys():\n",
    "                num_feature_occurred[feat] += 1\n",
    "            break\n",
    "    \n",
    "    for i, model_name in enumerate(model_names):\n",
    "        merged_df.insert(\n",
    "            i+1, model_name+f\"_Top_{top_k_percent}%_Prob\",\n",
    "            merged_df[\"Features\"].map(lambda feat: top_k_freq_dict[model_name][feat]/num_feature_occurred[feat] if feat in feat_dict else 0)\n",
    "            )\n",
    "    # Sort the DataFrame by Top_K%_Probability\n",
    "    merged_df = merged_df.sort_values(\n",
    "        by=[model_name + f\"_Top_{top_k_percent}%_Prob\" for model_name in model_names] + \\\n",
    "           [model_name + f\"_Top_{top_k_percent}%_Freq\" for model_name in model_names],\n",
    "        ascending=False)\n",
    "\n",
    "    # Cleaning up the merged_df\n",
    "    # Round all the entries to 2 decimal places\n",
    "    merged_df = merged_df.round(2)\n",
    "    # Remove rows with NaN in all except the column \"Features\", i.e. the feature was not used by any model\n",
    "    merged_df = merged_df.dropna(how=\"all\", subset=merged_df.columns[1:])\n",
    "    \n",
    "    print_and_log(f\"Total number of features: {len(merged_df)}\")\n",
    "\n",
    "    # Save the merged DataFrame\n",
    "    merged_df_path = os.path.join(plot_dir, f\"merged_feature_scores_datasets{''.join(merged_df_prefixes)}.csv\")\n",
    "    merged_df.to_csv(merged_df_path, index=False)\n",
    "    print_and_log(f\"Merged DataFrame saved to {merged_df_path}\")\n",
    "    return merged_df, top_k_freq_dict\n",
    "\n",
    "df_merged, top_k_freq_dict = tabularize_feature_ranks(\n",
    "    all_top_features,\n",
    "    model_names=[\"RF\", \"LR\"],\n",
    "    merged_df_prefixes=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
    "    do_print=False\n",
    ")\n",
    "\n",
    "df_merged, top_k_freq_dict = tabularize_feature_ranks(\n",
    "    all_top_features,\n",
    "    model_names=[\"RF\", \"LR\"],\n",
    "    merged_df_prefixes=[df_name[0] for df_name in all_top_features.keys()],\n",
    "    do_print=False\n",
    ")\n",
    "# print_and_log(df_merged.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Conduct experiments for determining the cumulative effect of the features on the model performance\n",
    "# For each dataset, train the models on the top-1 most important feature, then top-2, top-3, ...\n",
    "# Save the results of each experiment in a dictionary\n",
    "# Import sleep module to allow the program to pause for a few seconds\n",
    "import time\n",
    "# def ... TODO: wrap the following code into a neat, reusable function\n",
    "num_folds = 50\n",
    "model_name = \"Random Forest\"\n",
    "target_column = \"POS_did_the_patient_receive_pm\"\n",
    "metrics_df = pd.DataFrame(columns=metrics_df_columns)\n",
    "# Create a dictionary for holding the DataFrames for plotting\n",
    "# Schema: {\"Dataset1\": {\"Top1_feature\": metrics_df1, \"Top2_feature\": metrics_df2, ...}, ...}\n",
    "plot_dict2 = defaultdict(OrderedDict)\n",
    "# Re-use the all_top_features dictionary for deciding the order of the features to use\n",
    "\n",
    "def plot_num_features_vs_metrics(all_top_features, model_name, target_column, metrics_df, plot_dict2, plot_dir):\n",
    "    \n",
    "    for df_name in all_top_features:\n",
    "        if not (\"1.0\" in df_name):\n",
    "            continue\n",
    "        # Create a DataFrame for the top-k most important feature\n",
    "        # Sort all features by feature scores\n",
    "        all_features_sorted = [f[0] for f in sorted(all_top_features[df_name][model_name].items(), key=lambda x: x[1], reverse=True)]\n",
    "        num_features = len(all_features_sorted)\n",
    "        df_all_features = dfs_std[df_name]\n",
    "        for k in range(0, num_features+1):\n",
    "            if k == 0:\n",
    "                # Random noise baseline\n",
    "                top_k_features = \"random_noise_baseline\"\n",
    "                print_and_log(f\"Processing {df_name} with top-{k} features out of {num_features}. This feature is random noise baseline.\")\n",
    "                df_top_k_features = df_all_features[[target_column]]\n",
    "                noise_data = np.random.rand(len(df_top_k_features))\n",
    "                df_top_k_features.insert(0, \"0_random_noise_baseline\", noise_data)\n",
    "                assert len(df_top_k_features.columns) == 2\n",
    "            else:\n",
    "                # Get the top-k most important features\n",
    "                top_k_features = all_features_sorted[:k]\n",
    "                print_and_log(f\"Processing {df_name} with top-{k} features out of {num_features}. The k-th is {top_k_features[-1]}\")\n",
    "                # Create a DataFrame for the top-k most important features, and the target variable\n",
    "                df_top_k_features = df_all_features[top_k_features + [target_column]]\n",
    "                assert len(df_top_k_features.columns) == k + 1\n",
    "            metrics_df, feature_scores = build_classifiers(df_top_k_features, df_name, num_folds=num_folds)\n",
    "            # print metrics_df, without index\n",
    "            print_and_log(\"\")\n",
    "            print_and_log(metrics_df.to_string(index=False, justify=\"right\"))\n",
    "            print_and_log(\"-\"*30)\n",
    "            # Add the DataFrame to the dictionary for plotting later\n",
    "            plot_dict2[df_name][k] = metrics_df\n",
    "            # Sleep for a few seconds to cool down the hardware\n",
    "            time.sleep(3)\n",
    "        print(\"=\"*150)\n",
    "        # Plot the metrics on the top-k most important features\n",
    "        # The X-axis is the number of features, with the kth feature as label\n",
    "        # The Y-axis is the metrics, with three types of metrics shown in separate markers\n",
    "        # The Y-axis also shows the metric scores for each feature\n",
    "        # The metrics are AUC, F1, and Accuracy, which are saved in metrics_df\n",
    "        # The legend is the type of the metric\n",
    "        # Use tight layout\n",
    "        plt.tight_layout()\n",
    "        fig, ax = plt.subplots()\n",
    "        # Set the title of the figure\n",
    "        fig.suptitle(f\"{df_name} Feature Selection ({model_name})\")\n",
    "        marker_map = {\"AUC\": \"o\", \"F1\": \"s\", \"Accuracy\": \"^\"}\n",
    "        for metric_name in [\"AUC\", \"F1\", \"Accuracy\"]:\n",
    "            # Create figure\n",
    "            plt_name = f\"{df_name}_top_features_metrics.png\"\n",
    "            x_data = [i for i in range(1, num_features+1)]\n",
    "            # Append the feature name to each x_data\n",
    "            x_data = [\"0_random_noise_baseline\"] + [f\"{i}_{all_features_sorted[i-1]}\" for i in x_data]\n",
    "            model_idx = metrics_df[\"Model\"].values.tolist().index(model_name)\n",
    "            y_data = []\n",
    "            y_err = []\n",
    "            for metrics_df in plot_dict2[df_name].values():\n",
    "                # Get the data for plotting\n",
    "                y_data.append(metrics_df[\"Avg \" + metric_name].values[model_idx])\n",
    "                y_err.append(metrics_df[\"SE \" + metric_name].values[model_idx])\n",
    "            # Plot the data\n",
    "            ax.errorbar(\n",
    "                x_data,\n",
    "                y_data,\n",
    "                yerr=y_err,\n",
    "                marker=marker_map[metric_name],\n",
    "                label=metric_name + \" (SE)\",\n",
    "                ms=2,\n",
    "                capsize=2,\n",
    "                barsabove=True,\n",
    "                elinewidth=2\n",
    "            )\n",
    "            # Rotate the x-axis labels\n",
    "        # Add feature scores\n",
    "        y_data = [0]\n",
    "        for feature, score in sorted(all_top_features[df_name][model_name].items(), key=lambda x: x[1], reverse=True):\n",
    "            y_data.append(score)\n",
    "        # Add 0.2 to y_data to make the plot look better\n",
    "        y_data = [y + 0.2 for y in y_data]\n",
    "        ax.plot(x_data, y_data, marker=\"x\", label=f\"Feature Score + 0.2 ({model_name})\")\n",
    "        # Set the marker size to smaller sizes so error bars can be seen\n",
    "        # Make the x-axis labels smaller if len_x_data is too long\n",
    "        x_tick_size = 10 if len(x_data) < 30 else 6\n",
    "        plt.xticks(rotation=-45, ha=\"left\", size=x_tick_size)\n",
    "        # Add legend\n",
    "        ax.legend(loc=\"best\")\n",
    "        # Enforce the range of the y-axis\n",
    "        ax.set_ylim(0.2, 1.0)\n",
    "        fig.set_size_inches(len(x_data) * 0.1 + 5, 9)\n",
    "        # Show major gridlines\n",
    "        ax.grid(True, which=\"major\", linestyle=\"-\")\n",
    "        # Show minor gridlines\n",
    "        ax.grid(True, which=\"minor\", linestyle=\"--\", alpha=0.2)\n",
    "        plt.show()\n",
    "        # Save the figure\n",
    "        # Adjust plot size, let the width be proportional to the length of x-data\n",
    "        plt_path = os.path.join(plot_dir, plt_name)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(plt_path, dpi=500)\n",
    "        \n",
    "        \n",
    "plot_num_features_vs_metrics(all_top_features, model_name, target_column, metrics_df, plot_dict2, plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Backward step-wise feature selection\n",
    "\n",
    "# Conduct experiments for determining the cumulative effect of the features on the model performance\n",
    "# For each dataset, train the models on the top-k most important feature, then top-(k-1), top-(k-2), ...\n",
    "def backward_feature_selection(all_top_features, model_name, target_column, metrics_df, plot_dict3, plot_dir, standardize, num_folds=3, impute_max_iter=30):\n",
    "    \n",
    "    for df_name in all_top_features:\n",
    "        if not (\"1.0\" in df_name):\n",
    "            continue\n",
    "        # Create a DataFrame for the top-k most important feature\n",
    "        # Sort all features by feature scores\n",
    "        all_features_sorted = [f[0] for f in sorted(all_top_features[df_name][model_name].items(), key=lambda x: x[1], reverse=True)]\n",
    "        num_features = len(all_features_sorted)\n",
    "        df_all_features = dfs_std[df_name]\n",
    "        df_all_features = df_all_features.dropna(axis=1, how=\"all\")\n",
    "        # If standardize is True, standardize the data\n",
    "        if standardize:\n",
    "            df_all_features = standardize_data(df_all_features)\n",
    "        # Keep track of the bottom feature scores\n",
    "        lowest_feature_scores = [0]\n",
    "        lowest_feature_names = []\n",
    "        for k in range(num_features, -1, -1):\n",
    "            if k == 0:\n",
    "                # Random noise baseline\n",
    "                top_k_features = \"random_noise_baseline\"\n",
    "                lowest_feature_names.append(\"0_random_noise_baseline\")\n",
    "                print_and_log(f\"Processing {df_name} with top-{k} features out of {num_features}. This feature is random noise baseline.\")\n",
    "                df_top_k_features = df_all_features[[target_column]]\n",
    "                noise_data = np.random.rand(len(df_top_k_features))\n",
    "                df_top_k_features.insert(0, \"0_random_noise_baseline\", noise_data)\n",
    "                assert len(df_top_k_features.columns) == 2\n",
    "                lowest_feature_scores.append(0)\n",
    "            elif k == num_features:\n",
    "                top_k_features = f\"{k}_all_features\"\n",
    "                lowest_feature_names.append(top_k_features)\n",
    "                print_and_log(f\"Processing {df_name} with top-{k} features out of {num_features}. This feature is all features.\")\n",
    "                df_top_k_features = df_all_features.copy()\n",
    "                assert len(df_top_k_features.columns) == num_features + 1\n",
    "            else:\n",
    "                # Assert feature scores are sorted in descending order\n",
    "                assert list(feature_scores.items()) == list(sorted(feature_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "                # Keep the top-k features and remove the rest, using feature_scores from previous iteration\n",
    "                top_k_features = list(feature_scores.keys())[:-1]\n",
    "                removed_feature = list(feature_scores.keys())[-1]\n",
    "                assert len(top_k_features) == k\n",
    "                lowest_feature_scores.append(feature_scores[removed_feature])\n",
    "                lowest_feature_names.append(f\"{k}_{removed_feature}\")\n",
    "                print_and_log(f\"Processing {df_name} with top-{k} features out of {num_features}. The last removed feature was {removed_feature}.\")\n",
    "                # Create a DataFrame for the top-k most important features, and the target variable\n",
    "                df_top_k_features = df_all_features[top_k_features + [target_column]]\n",
    "                assert len(df_top_k_features.columns) == k + 1\n",
    "                assert removed_feature not in df_top_k_features.columns\n",
    "            # Print the number of missing values in df_top_k_features if any\n",
    "            if df_top_k_features.isnull().values.any():\n",
    "                print_and_log(f\"{df_name} has {df_top_k_features.isnull().sum().sum()} missing values before imputing.\")\n",
    "            # Impute missing values in df_top_k_features using Random Forest\n",
    "            df_top_k_features_imputed = impute_missing_value(df_top_k_features, target_column, max_iter=impute_max_iter)\n",
    "            assert df_top_k_features_imputed.isnull().values.any() == False\n",
    "            metrics_df, feature_scores = build_classifiers(df_top_k_features_imputed, df_name, num_folds=num_folds)\n",
    "            # Keep feature scores from chosen model_name only, format is {\"top-1st-feature\": score1, \"top-2nd-feature\": score2, ...}\n",
    "            feature_scores = feature_scores[model_name] \n",
    "            # Assert feature scores are sorted in descending order\n",
    "            assert list(feature_scores.items()) == list(sorted(feature_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "            # print metrics_df, without index\n",
    "            print_and_log(\"\")\n",
    "            print_and_log(metrics_df.to_string(index=False, justify=\"right\"))\n",
    "            print_and_log(\"-\"*30)\n",
    "            # Add the DataFrame to the dictionary for plotting later\n",
    "            plot_dict3[df_name][k] = metrics_df\n",
    "            # Sleep for a few seconds to cool down the hardware\n",
    "            time.sleep(3)\n",
    "        print(\"=\"*150)\n",
    "        # Plot the metrics on the top-k most important features\n",
    "        # The X-axis is the number of features, with the kth feature as label\n",
    "        # The Y-axis is the metrics, with three types of metrics shown in separate markers\n",
    "        # The Y-axis also shows the metric scores for each feature\n",
    "        # The metrics are AUC, F1, and Accuracy, which are saved in metrics_df\n",
    "        # The legend is the type of the metric\n",
    "        # Use tight layout\n",
    "        plt.tight_layout()\n",
    "        fig, ax = plt.subplots()\n",
    "        # Set the title of the figure\n",
    "        fig.suptitle(f\"{df_name} Feature Selection ({model_name})\")\n",
    "        marker_map = {\"AUC\": \"o\", \"F1\": \"s\", \"Accuracy\": \"^\"}\n",
    "        for metric_name in [\"AUC\", \"F1\", \"Accuracy\"]:\n",
    "            # Create figure\n",
    "            plt_name = f\"{df_name}_top_features_metrics.png\"\n",
    "            # x_data = [i for i in range(1, num_features+1)]\n",
    "            # Append the feature name to each x_data\n",
    "            # x_data = [\"0_random_noise_baseline\"] + [f\"{i}_{all_features_sorted[i-1]}\" for i in x_data]\n",
    "            x_data = lowest_feature_names\n",
    "            model_idx = metrics_df[\"Model\"].values.tolist().index(model_name)\n",
    "            y_data = []\n",
    "            y_err = []\n",
    "            for metrics_df in plot_dict3[df_name].values():\n",
    "                # Get the data for plotting\n",
    "                y_data.append(metrics_df[\"Avg \" + metric_name].values[model_idx])\n",
    "                y_err.append(metrics_df[\"SE \" + metric_name].values[model_idx])\n",
    "            # Plot the data\n",
    "            ax.errorbar(\n",
    "                x_data,\n",
    "                y_data,\n",
    "                yerr=y_err,\n",
    "                marker=marker_map[metric_name],\n",
    "                label=metric_name + \" (SE)\",\n",
    "                ms=2,\n",
    "                capsize=2,\n",
    "                barsabove=True,\n",
    "                elinewidth=2\n",
    "            )\n",
    "\n",
    "        ax.plot(x_data, lowest_feature_scores, marker=\"x\", label=f\"Removed Feature's Score ({model_name})\")\n",
    "        # Set the marker size to smaller sizes so error bars can be seen\n",
    "        # Make the x-axis labels smaller if len_x_data is too long\n",
    "        x_tick_size = 10 if len(x_data) < 30 else 6\n",
    "        plt.xticks(rotation=-45, ha=\"left\", size=x_tick_size)\n",
    "        # Add legend\n",
    "        ax.legend(loc=\"best\")\n",
    "        # Enforce the range of the y-axis\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        fig.set_size_inches(len(x_data) * 0.1 + 5, 9)\n",
    "        # Show major gridlines\n",
    "        ax.grid(True, which=\"major\", linestyle=\"-\")\n",
    "        # Show minor gridlines\n",
    "        ax.grid(True, which=\"minor\", linestyle=\"--\", alpha=0.2)\n",
    "        plt.show()\n",
    "        # Save the figure\n",
    "        # Adjust plot size, let the width be proportional to the length of x-data\n",
    "        plt_path = os.path.join(plot_dir, plt_name)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(plt_path, dpi=500)\n",
    "        \n",
    "\n",
    "for standardize in True, False:\n",
    "    dir_name = \"plots_backward_selection_standardized\" if standardize else \"plots_backward_selection_not_standardized\"\n",
    "    plot_dir_backwards = os.path.join(dir_to_df, dir_name) \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(plot_dir_backwards):\n",
    "        os.makedirs(plot_dir_backwards)\n",
    "\n",
    "    model_name = \"Random Forest\"\n",
    "    target_column = \"POS_did_the_patient_receive_pm\"\n",
    "    metrics_df = pd.DataFrame(columns=metrics_df_columns)\n",
    "    # Create a dictionary for holding the DataFrames for plotting\n",
    "    # Schema: {\"Dataset1\": {\"TopK_feature\": metrics_df1, \"Top(K-1)_feature\": metrics_df2, ...}, ...}\n",
    "    plot_dict3 = defaultdict(OrderedDict)\n",
    "    # Re-use the all_top_features dictionary for deciding the order of the features to use\n",
    "    backward_feature_selection(all_top_features, model_name, target_column, metrics_df, plot_dict3, plot_dir_backwards, standardize=False, num_folds=5, impute_max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49e64fde10219d3ab96bfbc338b28578e123987725ce81113aeea3e8142c8584"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
