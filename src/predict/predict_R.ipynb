{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(randomForest): there is no package called ‘randomForest’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(randomForest): there is no package called ‘randomForest’\nTraceback:\n",
      "1. library(randomForest)"
     ]
    }
   ],
   "source": [
    "# A notebook in R Language\n",
    "# Use Machine Learning to predict the probability of needing Post-Mastectom Radiotherapy\n",
    "# Author: Yifu (Charles) Chen\n",
    "\n",
    "### Install packages ###\n",
    "# Please install the following packages before running this notebook:\n",
    "# install.packages(\"standardize\")\n",
    "# install.packages(\"randomForest\")\n",
    "\n",
    "### Import libraries ###\n",
    "# Logistic Regression, Random Forest, and XGBoost\n",
    "library(randomForest)\n",
    "library(xgboost)\n",
    "# standardization\n",
    "library(data.table)\n",
    "# cross-validation\n",
    "library(crossval)\n",
    "# performance metrics\n",
    "library(performance)\n",
    "# plotting\n",
    "library(ggplot2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in standardize(df[-c(\"POS_did_the_patient_receive_pm\")]): could not find function \"standardize\"\n",
     "output_type": "error",
     "traceback": [
      "Error in standardize(df[-c(\"POS_did_the_patient_receive_pm\")]): could not find function \"standardize\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory of DataFrames\n",
    "dir_to_df <- \"/Users/yifu/PycharmProjects/Radiotherapy-Prediction/data/experiments/May18 Datasets for Experiments Table Debugged\"\n",
    "# Assume all files in directory are CSV DataFrame files\n",
    "paths_to_df <- list.files(dir_to_df, full.names = TRUE)\n",
    "paths_to_df\n",
    "\n",
    "# Read each DataFrame file\n",
    "dfs <- list()\n",
    "for (path in paths_to_df) {\n",
    "    temp_df <- read.csv(path, header = TRUE, sep = \",\")\n",
    "    dfs[[path]] <- temp_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in standardize(df, na.rm = TRUE): could not find function \"standardize\"\n",
     "output_type": "error",
     "traceback": [
      "Error in standardize(df, na.rm = TRUE): could not find function \"standardize\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# The target variable is named \"POS_did_the_patient_receive_pm\"\n",
    "# Standardize the data by removing the mean and scaling to unit variance\n",
    "for (df in dfs) {\n",
    "    df <- standardize(df, na.rm = TRUE)\n",
    "}\n",
    "\n",
    "\n",
    "# For each DataFrame, standardize \n",
    "for (df_path in paths_to_df) {\n",
    "    # Read the DataFrame\n",
    "    df <- dfs[[df_path]]\n",
    "    # Standardize all the DataFrame columns except POS_did_the_patient_receive_pm, with mean 0 and standard deviation 1\n",
    "    df_std <- standardize(df[-c(\"POS_did_the_patient_receive_pm\")])\n",
    "    # Read a copy of the DataFrame\n",
    "    df_copy <- data.frame(df_std)\n",
    "    # Impute the DataFrame's missing values using KNN Imputation, with K=5\n",
    "    df_imputed <- knnimpute(df_copy, k = 5)\n",
    "    # Build a Logistic Regression Model\n",
    "    lr_model <- glm(POS_did_the_patient_receive_pm ~ ., data =  df_imputed, family = binomial)\n",
    "    # Build a Random Forest Model\n",
    "    rf_model <- rf(df$POS_did_the_patient_receive_pm ~ ., data = df_imputed, ntree = 100)\n",
    "    # Build a XGBoost Model\n",
    "    xgb_model <- xgb(df$POS_did_the_patient_receive_pm ~ ., data = df_imputed, nround = 100)\n",
    "    # Save the models to the hashmap\n",
    "    models_map[[df_path]] <- list(LR = lr_model, RF = rf_model, XGB = xgb_model)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create a hashmap for saving the models for each DataFrame\n",
    "# Schema: {DataFrame_path_name: {LR: LR_Model, RF: RF_Model, XGB: XGB_Model}}\n",
    "models_map <- list()\n",
    "\n",
    "# Iterate through each DataFrame, and build Logistic Regression, Random Forest, and XGBoost Models to predict target column \"POS_did_the_patient_receive_pm\"\n",
    "for (df_path in paths_to_df) {\n",
    "    # Read the DataFrame\n",
    "    df <- dfs[[df_path]]\n",
    "    # Standardize all the DataFrame columns except POS_did_the_patient_receive_pm, with mean 0 and standard deviation 1\n",
    "    df_std <- standardize(df[-c(\"POS_did_the_patient_receive_pm\")])\n",
    "    # Read a copy of the DataFrame\n",
    "    df_copy <- data.frame(df_std)\n",
    "    # Impute the DataFrame's missing values using KNN Imputation, with K=5\n",
    "    df_imputed <- knnimpute(df_copy, k = 5)\n",
    "    # Build a Logistic Regression Model\n",
    "    lr_model <- glm(POS_did_the_patient_receive_pm ~ ., data =  df_imputed, family = binomial)\n",
    "    # Build a Random Forest Model\n",
    "    rf_model <- rf(df$POS_did_the_patient_receive_pm ~ ., data = df_imputed, ntree = 100)\n",
    "    # Build a XGBoost Model\n",
    "    xgb_model <- xgb(df$POS_did_the_patient_receive_pm ~ ., data = df_imputed, nround = 100)\n",
    "    # Save the models to the hashmap\n",
    "    models_map[[df_path]] <- list(LR = lr_model, RF = rf_model, XGB = xgb_model)\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
