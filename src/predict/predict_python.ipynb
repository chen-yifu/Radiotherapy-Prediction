{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Machine Learning to predict the probability of needing Post-Mastectomy Radiotherapy\n",
    "Author: Yifu (Charles) Chen\n",
    "\n",
    "A notebook in Python Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import modules ###\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import re\n",
    "# Machine Learning Modules for Random Forest, Logistic Regression, and XGBoost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "# Metrics\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup no print limits and etc.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "class bcolors:\n",
    "    # Helper class to print in terminal with colors\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    NORMAL = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Directory of DataFrames\n",
    "dir_to_df = \"/Users/yifu/PycharmProjects/Radiotherapy-Prediction/data/experiments/May26 Datasets for Experiments Table (enhanced expert cols)\"\n",
    "\n",
    "# Path to log file\n",
    "log_path = os.path.join(dir_to_df, \"log.txt\")\n",
    "\n",
    "# Create a new log file from scratch, regardless if one exists\n",
    "with open(log_path, \"w\") as log_file:\n",
    "    log_file.write(\"\")\n",
    "\n",
    "def print_and_log(*args, **kwargs):\n",
    "    # Helper function to print and log\n",
    "    # Can write DataFrame to log file too\n",
    "    print(*args, **kwargs)\n",
    "    with open(log_path, \"a\") as log_file:\n",
    "        if type(args[0]) == pd.DataFrame:\n",
    "            log_file.write(args[0].to_string() + \"\\n\")\n",
    "        else:\n",
    "            log_file.write(\"|| \".join([str(a) for a in args]) + \"\\n\")\n",
    "\n",
    "    \n",
    "# Assume all files in directory are CSV DataFrame files\n",
    "paths_to_df = glob.glob(os.path.join(dir_to_df, \"*.csv\"))\n",
    "\n",
    "# Read each DataFrame file\n",
    "dfs = OrderedDict()\n",
    "for i, path in enumerate(paths_to_df):\n",
    "    df_name = path.replace(dir_to_df, \"\")\n",
    "    df = pd.read_csv(path)\n",
    "    if i == len(paths_to_df) - 1:\n",
    "        print(\"Kept the largest DF\")\n",
    "        df_all = df.copy()\n",
    "        # dfs[\"df_all\"] = df\n",
    "    # Drop \"PRE_record_id\" column, if it exists\n",
    "    if \"PRE_record_id\" in df.columns:\n",
    "        df = df.drop(columns=[\"PRE_record_id\"], axis=1)\n",
    "    dfs[df_name] = df\n",
    "# Sorted the dict by path name\n",
    "dfs = OrderedDict(sorted(dfs.items()))\n",
    "\n",
    "for k in dfs.keys():\n",
    "    print_and_log(k)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the data by removing the mean and scaling to unit variance\n",
    "# The target variable is named \"POS_did_the_patient_receive_pm\"\n",
    "\n",
    "dfs_std = OrderedDict()\n",
    "\n",
    "for df_name, df in dfs.items():\n",
    "    # Standardize all columns except the target column \"POS_did_the_patient_receive_pm\"\n",
    "    df_std = df.copy()\n",
    "    df_std.drop([\"POS_did_the_patient_receive_pm\"], axis=1, inplace=True)\n",
    "    df_std = (df_std - df_std.mean()) / df_std.std()\n",
    "    df_std = df_std.copy()\n",
    "    # Concatenate the target column back\n",
    "    df_std[\"POS_did_the_patient_receive_pm\"] = df[\"POS_did_the_patient_receive_pm\"]\n",
    "    # Convert the target column to binary\n",
    "    df_std[\"POS_did_the_patient_receive_pm\"] = df_std[\"POS_did_the_patient_receive_pm\"] > 0\n",
    "    dfs_std[df_name] = df_std\n",
    "\n",
    "len(dfs_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Machine Learning Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /0_PRE-alan-heuristic7cols.csv...\n",
      "Fold 1... Fold 2... Fold 3... Fold 4... Fold 5... Fold 6... Fold 7... Fold 8... Fold 9... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 150>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=149'>150</a>\u001b[0m \u001b[39mfor\u001b[39;00m df_name, df \u001b[39min\u001b[39;00m dfs_std\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=150'>151</a>\u001b[0m     print_and_log(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mdf_name\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=151'>152</a>\u001b[0m     print_df, feature_scores \u001b[39m=\u001b[39m build_classifiers(df, df_name)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=152'>153</a>\u001b[0m     \u001b[39m# Transpose the DataFrame before printing it\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=153'>154</a>\u001b[0m     print_and_log(print_df\u001b[39m.\u001b[39mT)\n",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb Cell 10'\u001b[0m in \u001b[0;36mbuild_classifiers\u001b[0;34m(df, df_name, num_folds)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=54'>55</a>\u001b[0m models[fold] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mLogistic Regression\u001b[39m\u001b[39m\"\u001b[39m: LogisticRegression(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=55'>56</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mRandom Forest\u001b[39m\u001b[39m\"\u001b[39m: RandomForestClassifier(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=56'>57</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mXGBoost\u001b[39m\u001b[39m\"\u001b[39m: XGBClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=57'>58</a>\u001b[0m                 }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=58'>59</a>\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models[fold]\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=59'>60</a>\u001b[0m     \u001b[39m# Train each model on the target column POS_did_the_patient_receive_pm\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=60'>61</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=61'>62</a>\u001b[0m         df_train\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mPOS_did_the_patient_receive_pm\u001b[39;49m\u001b[39m\"\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=62'>63</a>\u001b[0m         df_train[\u001b[39m\"\u001b[39;49m\u001b[39mPOS_did_the_patient_receive_pm\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=63'>64</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=64'>65</a>\u001b[0m     \u001b[39m# Predict the validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=65'>66</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=66'>67</a>\u001b[0m         df_val\u001b[39m.\u001b[39mdrop([\u001b[39m\"\u001b[39m\u001b[39mPOS_did_the_patient_receive_pm\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000009?line=67'>68</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py?line=529'>530</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py?line=530'>531</a>\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py?line=531'>532</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1378'>1379</a>\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1379'>1380</a>\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1380'>1381</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1381'>1382</a>\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1382'>1383</a>\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1383'>1384</a>\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1396'>1397</a>\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1397'>1398</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1399'>1400</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1400'>1401</a>\u001b[0m     params,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1401'>1402</a>\u001b[0m     train_dmatrix,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1402'>1403</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1403'>1404</a>\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1404'>1405</a>\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1405'>1406</a>\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1406'>1407</a>\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1407'>1408</a>\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1408'>1409</a>\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1409'>1410</a>\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1410'>1411</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1411'>1412</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1413'>1414</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py?line=1414'>1415</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py?line=529'>530</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py?line=530'>531</a>\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py?line=531'>532</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py?line=179'>180</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py?line=180'>181</a>\u001b[0m     bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m--> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py?line=181'>182</a>\u001b[0m     \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39;49mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py?line=182'>183</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py?line=184'>185</a>\u001b[0m bst \u001b[39m=\u001b[39m cb_container\u001b[39m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py:222\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=218'>219</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=219'>220</a>\u001b[0m             cast(List[\u001b[39mfloat\u001b[39m], metric_history)\u001b[39m.\u001b[39mappend(cast(\u001b[39mfloat\u001b[39m, x))\n\u001b[0;32m--> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=221'>222</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mafter_iteration\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=222'>223</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=223'>224</a>\u001b[0m     model,\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=224'>225</a>\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=225'>226</a>\u001b[0m     dtrain: DMatrix,\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=226'>227</a>\u001b[0m     evals: Optional[List[Tuple[DMatrix, \u001b[39mstr\u001b[39m]]],\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=227'>228</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=228'>229</a>\u001b[0m     \u001b[39m'''Function called after training iteration.'''\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/xgboost/callback.py?line=229'>230</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_cv:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize a dictionary for holding the models for each DataFrame\n",
    "# Schema: {\"DataFrame Name\": {\"Model Name\": Model Object, ...}, ...}\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "\n",
    "all_models = defaultdict(dict)\n",
    "\n",
    "# The print_df contains the dataframe, model, and the average CV accuracy, AUC, and the top 6 features and their scores\n",
    "# print_df_columns = [\"Dataset\", \"Model\", \"Avg CV Accuracy\", \"Avg CV AUC\", \"Avg CV F1\", \"Feature_1\", \"Score_1\", \"Feature_2\", \"Score_2\", \n",
    "#                     \"Feature_3\", \"Score_3\", \"Feature_4\", \"Score_4\", \"Feature_5\", \"Score_5\", \"Feature_6\", \"Score_6\"]\n",
    "\n",
    "print_df_columns = [\"Dataset\", \"Model\"] + list(itertools.chain(*[[\"Avg \" + m, \"SE \" + m] for m in [\"Accuracy\", \"AUC\", \"F1\"]]))\n",
    "\n",
    "def build_classifiers(df: pd.DataFrame, df_name: str, num_folds: int=15) -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    For each DataFrame, build the following classifiers:\n",
    "        Logistic Regression\n",
    "        Random Forest\n",
    "        XGBoost\n",
    "    Args:\n",
    "        df (pd.DataFrame): the DataFrame to build the classifiers for\n",
    "        df_name (str): the name of the DataFrame\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Impute missing values with KNN\n",
    "    from sklearn.impute import KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    # Drop columns that are all NaN, also drop the target column\n",
    "    df_drop_na = df.dropna(axis=1, how=\"all\")\n",
    "    df_drop_na = df_drop_na.drop(columns=[\"POS_did_the_patient_receive_pm\"])\n",
    "    # Impute the missing values\n",
    "    df_imp = pd.DataFrame(imputer.fit_transform(df_drop_na), columns=df_drop_na.columns)\n",
    "    # Put the target back\n",
    "    df_imp[\"POS_did_the_patient_receive_pm\"] = df[\"POS_did_the_patient_receive_pm\"]\n",
    "    df = df_imp.copy()\n",
    "\n",
    "    assert df.isnull().sum().sum() == 0\n",
    "\n",
    "    # Initialize a dictionary for holding the models for each DataFrame\n",
    "    # Schema: {\"Fold 1\": {\"Model Name\": Model Object, ...}, ...}\n",
    "    models = defaultdict(dict)\n",
    "    performance = defaultdict(dict)\n",
    "    # Train each model using 5-fold cross-validation, repeated 10 times to get error bars\n",
    "    # for i in range(num_cvs):\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(df)):\n",
    "        fold = fold + 1\n",
    "        print(\"Fold {}\".format(fold), end=\"... \")\n",
    "        # Split the DataFrame into training and validation sets\n",
    "        df_train, df_val = df.iloc[train_index], df.iloc[test_index]\n",
    "        # Build the classifiers\n",
    "        models[fold] = {\"Logistic Regression\": LogisticRegression(),\n",
    "                        \"Random Forest\": RandomForestClassifier(),\n",
    "                        \"XGBoost\": XGBClassifier()\n",
    "                        }\n",
    "        for model_name, model in models[fold].items():\n",
    "            # Train each model on the target column POS_did_the_patient_receive_pm\n",
    "            model.fit(\n",
    "                df_train.drop([\"POS_did_the_patient_receive_pm\"], axis=1),\n",
    "                df_train[\"POS_did_the_patient_receive_pm\"]\n",
    "                )\n",
    "            # Predict the validation set\n",
    "            y_pred = model.predict(\n",
    "                df_val.drop([\"POS_did_the_patient_receive_pm\"], axis=1)\n",
    "            )\n",
    "            # Calculate the accuracy of the model\n",
    "            accuracy = np.mean(y_pred == df_val[\"POS_did_the_patient_receive_pm\"])\n",
    "            # Calcuilate the F1\n",
    "            F1 = f1_score(y_true=df_val[\"POS_did_the_patient_receive_pm\"], y_pred=y_pred)\n",
    "            # Predict the probability of the validation set\n",
    "            y_pred_proba = model.predict_proba(df_val.drop([\"POS_did_the_patient_receive_pm\"], axis=1))[:, 1]\n",
    "            # Calculate the AUC of the model\n",
    "            auc = metrics.roc_auc_score(df_val[\"POS_did_the_patient_receive_pm\"], y_pred_proba)\n",
    "            if model_name != \"Logistic Regression\":\n",
    "                # Get the features for the model\n",
    "                feature_importances = pd.Series(model.feature_importances_, index=df_train.drop([\"POS_did_the_patient_receive_pm\"], axis=1).columns)\n",
    "            else:\n",
    "                # The features for the Logistic Regression model are the coefficients\n",
    "                # Take absolute value of the coefficients\n",
    "                feature_importances = pd.Series(np.abs(model.coef_[0]), index=df_train.drop([\"POS_did_the_patient_receive_pm\"], axis=1).columns)\n",
    "            # Store the accuracy, AUC, and features for the model\n",
    "            performance[model_name][fold] = {\"accuracy\": accuracy, \"auc\": auc, \"F1\": F1, \"top_features\": feature_importances}\n",
    "    \n",
    "    # Consolidate the top features for each model\n",
    "    # Schema: {\"Model Name\": {\"Feature_1\": Score_1, ...}, ...}\n",
    "    feature_scores = defaultdict(lambda: defaultdict(float))\n",
    "    for model_name, fold in performance.items():\n",
    "        for fold_num, fold_performance in fold.items():\n",
    "            # Extract feature name and importance score\n",
    "            for feature_name, score in fold_performance[\"top_features\"].items():\n",
    "                feature_scores[model_name][feature_name] += score\n",
    "        # Divide the feature importance scores by the number of folds\n",
    "        for feature_name, score in feature_scores[model_name].items():\n",
    "            feature_scores[model_name][feature_name] /= len(fold)\n",
    "            # Round to 2 decimal places\n",
    "            feature_scores[model_name][feature_name] = round(feature_scores[model_name][feature_name], 4)\n",
    "    \n",
    "    # Print the performance of each model, including averaged across folds\n",
    "    # DataFrame for printing results in a nice format\n",
    "    # Columns: Dataset, Model, Avg CV Accuracy, SE Accuracy, Avg CV AUC, SE AUC, Avg CV F1, SE F1\n",
    "    print_df = pd.DataFrame(columns=print_df_columns)\n",
    "    for model_name, fold in performance.items():\n",
    "        accuracy = round(np.mean([fold[fold_num][\"accuracy\"] for fold_num in fold.keys()]), 4)\n",
    "        auc = round(np.mean([fold[fold_num][\"auc\"] for fold_num in fold.keys()]), 4)\n",
    "        F1 = round(np.mean([fold[fold_num][\"F1\"] for fold_num in fold.keys()]), 4)\n",
    "        accuracy_se = round(np.std([fold[fold_num][\"accuracy\"] for fold_num in fold.keys()]) / np.sqrt(len(fold)), 4)\n",
    "        auc_se = round(np.std([fold[fold_num][\"auc\"] for fold_num in fold.keys()]) / np.sqrt(len(fold)), 4)\n",
    "        F1_se = round(np.std([fold[fold_num][\"F1\"] for fold_num in fold.keys()]) / np.sqrt(len(fold)), 4)\n",
    "        # Convert metric and metric_se from float to string format\n",
    "        # accuracy_str = str(accuracy) + \" (\" + str(accuracy_se) + \")\"\n",
    "        # auc_str = str(auc) + \" (\" + str(auc_se) + \")\"\n",
    "        # F1_str = str(F1) + \" (\" + str(F1_se) + \")\"\n",
    "        # curr_df = pd.DataFrame(\n",
    "        #             [\n",
    "        #                 [df_name, model_name, accuracy_str, auc_str, F1_str] +\n",
    "        #                 [feat_1, score_1, feat_2, score_2, feat_3, score_3, feat_4, score_4, feat_5, score_5, feat_6, score_6]\n",
    "        #             ],\n",
    "        #             columns=print_df_columns\n",
    "        #         )\n",
    "        curr_df = pd.DataFrame(\n",
    "                    [\n",
    "                        [df_name, model_name, accuracy, accuracy_se, auc, auc_se, F1, F1_se]\n",
    "                    ],\n",
    "                    columns=print_df_columns\n",
    "                )\n",
    "        print_df = pd.concat(\n",
    "            [\n",
    "                print_df,\n",
    "                curr_df\n",
    "            ],\n",
    "            axis=0\n",
    "        )\n",
    "    # Print the DataFrame with nice formatting\n",
    "    # print_and_log(print_df)\n",
    "\n",
    "    # print_and_log(\"=\"*150)\n",
    "    return print_df, feature_scores\n",
    "\n",
    "\n",
    "# Build the classifiers for each DataFrame\n",
    "print_df = pd.DataFrame(columns=print_df_columns)\n",
    "# Create a dictionary for holding the DataFrames for plotting\n",
    "plot_dict = OrderedDict()\n",
    "# Create a dictionary for holding all the feature scores across datasets and models\n",
    "# Schema: {\"Dataset1\": {\"Model1\": {\"Feature_1\": Score_1, ...}, ...}, ...}\n",
    "all_top_features = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "for df_name, df in dfs_std.items():\n",
    "    print_and_log(f\"Processing {df_name}...\")\n",
    "    print_df, feature_scores = build_classifiers(df, df_name)\n",
    "    # Transpose the DataFrame before printing it\n",
    "    print_and_log(print_df.T)\n",
    "    model_names = feature_scores.keys()\n",
    "    for model in model_names:\n",
    "        print_and_log(\"\\n\" + \"-\" * 10 + f\"The most important features for {model}:\" + \"-\" * 10)\n",
    "        top_features = sorted(feature_scores[model].items(), key=lambda x: x[1], reverse=True)[:]\n",
    "        for i, (feat, score) in enumerate(top_features):\n",
    "            all_top_features[df_name][model][feat] = score\n",
    "            # If the feature is in the top 1/3, print it\n",
    "            if i < len(top_features) / 3:\n",
    "                print_and_log(f\"{feat}: {score}\", end=\"\\t\")\n",
    "        print_and_log(\"\")\n",
    "    print_and_log(\"=\"*150)\n",
    "    # Add the DataFrame to the dictionary for plotting later\n",
    "    plot_dict[df_name] = print_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use different proportion subsets of DataFrame and determine the performance\n",
    "# Sort df_all by \"PRE_record_id\"\n",
    "# df_all = df_all.sort_values(by=\"PRE_record_id\")\n",
    "# # Drop \"PRE_record_id\" column\n",
    "# df_all = df_all.drop([\"PRE_record_id\"], axis=1)\n",
    "# for percentile in range(10, 100, 10):\n",
    "#     percentage = percentile/100\n",
    "#     # Take the first percentage of the DataFrame\n",
    "#     df_subset = df_all.iloc[:int(len(df_all)*percentage)]\n",
    "#     # Train the classifiers on the subset\n",
    "#     print_df = build_classifiers(df_subset, f\"{percentage}% of DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg Accuracy</th>\n",
       "      <th>SE Accuracy</th>\n",
       "      <th>Avg AUC</th>\n",
       "      <th>SE AUC</th>\n",
       "      <th>Avg F1</th>\n",
       "      <th>SE F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/C_POS-1.0spars-expert-imputed128cols.csv</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.8274</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.0241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/C_POS-1.0spars-expert-imputed128cols.csv</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/C_POS-1.0spars-expert-imputed128cols.csv</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.8066</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.8839</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.7498</td>\n",
       "      <td>0.0223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Dataset                Model Avg Accuracy SE Accuracy Avg AUC  SE AUC  Avg F1   SE F1\n",
       "0  /C_POS-1.0spars-expert-imputed128cols.csv  Logistic Regression        0.794      0.0185  0.8274  0.0192  0.7403  0.0241\n",
       "0  /C_POS-1.0spars-expert-imputed128cols.csv        Random Forest       0.8163      0.0139  0.8889  0.0142  0.7551  0.0201\n",
       "0  /C_POS-1.0spars-expert-imputed128cols.csv              XGBoost       0.8066       0.015  0.8839  0.0136  0.7498  0.0223"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting libraries for machine learning experiments\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plot_dir = os.path.join(dir_to_df, \"plots\")\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "\n",
    "# Retrive the saved DataFrames, and plot the results\n",
    "# Plot the results for each DataFrame on a single plot\n",
    "# Reset plot parameters\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "for metric_name in [\"Accuracy\", \"AUC\", \"F1\"]:\n",
    "    y_data = []\n",
    "    errors = []\n",
    "    x_data = []\n",
    "    # Retrieve the performance for each model\n",
    "    for df_name, print_df in plot_dict.items():\n",
    "        # Iterate through the models of the DataFrame\n",
    "        for i, row in print_df.iterrows():\n",
    "            # If the model is the metric, add it to the list\n",
    "            model_name = row[\"Model\"]\n",
    "            # Use regular expression to retrieve the metric and its standard error\n",
    "            metric = row[\"Avg \" + metric_name]\n",
    "            error = row[\"SE \" + metric_name]\n",
    "            df_name = row[\"Dataset\"]\n",
    "            df_name = df_name.replace(\"/\", \"\").replace(\".csv\", \"\")\n",
    "            x_data.append(metric)\n",
    "            y_data.append(df_name + \" - \" + model_name)\n",
    "            errors.append(error)\n",
    "    # Create the plot\n",
    "    # The plot has spaces between the bars\n",
    "    plt.figure(figsize=(30, 16))\n",
    "    # Plot the gridlines\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    # The color of the bar should alternate between 3 colors\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]\n",
    "    # Make bars \n",
    "    plt.barh(y_data, x_data, xerr=errors, color=colors, align=\"center\")\n",
    "    # plt.barh(y_data, x_data, align=\"center\", alpha=0.8)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.xlabel(metric_name, fontsize=20)\n",
    "    plt.ylabel(\"Model\")\n",
    "    plt.title(f\"{metric_name} by Model\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(plot_dir, f\"{metric_name}.png\"))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Processing /0_PRE-alan-heuristic7cols.csv...\n",
      "/0_PRE-alan-heuristic7cols.csv: 2 features for Logistic Regression, 2 features for Random Forest, and 2 features for XGBoost\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000018?line=25'>26</a>\u001b[0m print_and_log(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(sorted_LR_features)\u001b[39m}\u001b[39;00m\u001b[39m features for Logistic Regression, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(sorted_RF_features)\u001b[39m}\u001b[39;00m\u001b[39m features for Random Forest, and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(sorted_XGB_features)\u001b[39m}\u001b[39;00m\u001b[39m features for XGBoost\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000018?line=26'>27</a>\u001b[0m \u001b[39m# Assert all the features are present in the sorted features dictionary\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000018?line=27'>28</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mset\u001b[39m(rank_LR_features\u001b[39m.\u001b[39mkeys()) \u001b[39m==\u001b[39m \u001b[39mset\u001b[39m(rank_RF_features\u001b[39m.\u001b[39mkeys()) \u001b[39m==\u001b[39m \u001b[39mset\u001b[39m(rank_XGB_features\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000018?line=28'>29</a>\u001b[0m \u001b[39m# Create a DataFrame with all the features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000018?line=29'>30</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mFeatures\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlist\u001b[39m(rank_LR_features\u001b[39m.\u001b[39mkeys())})\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for each dataset in all_top_features, build a DataFrame with the top features\n",
    "# The features for each model is ranked by their score\n",
    "# The most important features shared by all models are sorted to the top\n",
    "# Columns: Features | Logistic Regression | Random Forest| XGBoost\n",
    "# Row 1:    feature_1 | feature_1_rank_LR | feature_1_rank_RF | feature_1_rank_XGB\n",
    "# Row 2:    feature_2 | feature_2_rank_LR | feature_2_rank_RF | feature_2_rank_XGB\n",
    " \n",
    "# Schema: {\"Dataset1\": {\"Model1\": {\"Feature_1\": Score_1, ...}, ...}, ...}\n",
    "\n",
    "# We currently only consider the Random Forest model\n",
    "for dataset, model_dict in all_top_features.items():\n",
    "    print_and_log(\"-\"*50)\n",
    "    print_and_log(f\"Processing {dataset}...\")\n",
    "    LR_features = model_dict[\"Logistic Regression\"]\n",
    "    RF_features = model_dict[\"Random Forest\"]\n",
    "    XGB_features = model_dict[\"XGBoost\"]\n",
    "    # Sort the features by their scores\n",
    "    sorted_LR_features = sorted(LR_features.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_RF_features = sorted(RF_features.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_XGB_features = sorted(XGB_features.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Convert each score into a rank\n",
    "    rank_LR_features = {feat: i+1 for i, (feat, score) in enumerate(sorted_LR_features)}\n",
    "    rank_RF_features = {feat: i+1 for i, (feat, score) in enumerate(sorted_RF_features)}\n",
    "    rank_XGB_features = {feat: i+1 for i, (feat, score) in enumerate(sorted_XGB_features)}\n",
    "    # Print the number of features for each model\n",
    "    print_and_log(f\"{dataset}: {len(sorted_LR_features)} features for Logistic Regression, {len(sorted_RF_features)} features for Random Forest, and {len(sorted_XGB_features)} features for XGBoost\")\n",
    "    # Assert all the features are present in the sorted features dictionary\n",
    "    assert set(rank_LR_features.keys()) == set(rank_RF_features.keys()) == set(rank_XGB_features.keys())\n",
    "    # Create a DataFrame with all the features\n",
    "    df = pd.DataFrame({\"Features\": list(rank_LR_features.keys())})\n",
    "    # Add the ranks of LR to the DataFrame\n",
    "    df[\"LR_rank\"] = df[\"Features\"].map(rank_LR_features)\n",
    "    # Add the ranks of RF to the DataFrame\n",
    "    df[\"RF_rank\"] = df[\"Features\"].map(rank_RF_features)\n",
    "    # Add the ranks of XGB to the DataFrame\n",
    "    df[\"XGB_rank\"] = df[\"Features\"].map(rank_XGB_features)\n",
    "    # Sort the DataFrame by the ranks of the features\n",
    "    df = df.sort_values(by=[\"LR_rank\", \"RF_rank\", \"XGB_rank\"])\n",
    "    # Keep only the top 1/3 of features (the most important features)\n",
    "    df = df.iloc[:int(len(df)*1/3)]\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_PRE-alan-heuristic7cols\n",
      "\n",
      "Model: Random Forest\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Feature_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Feature_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000015?line=10'>11</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000015?line=11'>12</a>\u001b[0m print_and_log(\u001b[39m\"\u001b[39m\u001b[39mModel:\u001b[39m\u001b[39m\"\u001b[39m, model_name)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000015?line=12'>13</a>\u001b[0m top_features \u001b[39m=\u001b[39m [row[\u001b[39m\"\u001b[39;49m\u001b[39mFeature_1\u001b[39;49m\u001b[39m\"\u001b[39;49m], row[\u001b[39m\"\u001b[39m\u001b[39mFeature_2\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mFeature_3\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mFeature_4\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mFeature_5\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mFeature_6\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000015?line=13'>14</a>\u001b[0m feature_scores \u001b[39m=\u001b[39m [row[\u001b[39m\"\u001b[39m\u001b[39mScore_1\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mScore_2\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mScore_3\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mScore_4\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mScore_5\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39m\u001b[39mScore_6\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yifu/PycharmProjects/Radiotherapy-Prediction/src/predict/predict_python.ipynb#ch0000015?line=14'>15</a>\u001b[0m print_and_log(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTop Features: \u001b[39m\u001b[39m{\u001b[39;00mtop_features\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=954'>955</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=956'>957</a>\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=957'>958</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=959'>960</a>\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=960'>961</a>\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=961'>962</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=962'>963</a>\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=1065'>1066</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=1067'>1068</a>\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=1068'>1069</a>\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py?line=1069'>1070</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/yifu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Feature_1'"
     ]
    }
   ],
   "source": [
    "# # Print the Feature Importance\n",
    "# # Format:\n",
    "# # DataFrame | Model | Feature_1 | Score_1 | Feature_2 | Score_2 | Feature_3 | Score_3 | Feature_4 | Score_4 | Feature_5 | Score_5 | Feature_6 | Score_6\n",
    "# for df_name, print_df in plot_dict.items():\n",
    "#     df_name = df_name.replace(\"/\", \"\").replace(\".csv\", \"\")\n",
    "#     print_and_log(df_name)\n",
    "#     print()\n",
    "#     for i, row in print_df.iterrows():\n",
    "#         model_name = row[\"Model\"]\n",
    "#         if model_name == \"Logistic Regression\":\n",
    "#             continue\n",
    "#         print_and_log(\"Model:\", model_name)\n",
    "#         top_features = [row[\"Feature_1\"], row[\"Feature_2\"], row[\"Feature_3\"], row[\"Feature_4\"], row[\"Feature_5\"], row[\"Feature_6\"]]\n",
    "#         feature_scores = [row[\"Score_1\"], row[\"Score_2\"], row[\"Score_3\"], row[\"Score_4\"], row[\"Score_5\"], row[\"Score_6\"]]\n",
    "#         print_and_log(f\"Top Features: {top_features}\")\n",
    "#         print_and_log(f\"Feature Scores: {feature_scores}\")\n",
    "#         print()\n",
    "#     print_and_log(\"-\"* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the most important features and scores for each model\n",
    "# # Create subplots for each DataFrame\n",
    "# for df_name, print_df in plot_dict.items():\n",
    "#     df_name = df_name.replace(\"/\", \"\").replace(\".csv\", \"\")\n",
    "#     # Create a plot for the top 6 important features of each model\n",
    "#     # Y-Axis: Model + Feature Name\n",
    "#     # X-Axis: Feature importance score\n",
    "#     # Create subplots \n",
    "#     for i, row in print_df.iterrows():\n",
    "#         top_features = [row[\"Feature_1\"], row[\"Feature_2\"], row[\"Feature_3\"], row[\"Feature_4\"], row[\"Feature_5\"], row[\"Feature_6\"]]\n",
    "#         feature_scores = [row[\"Score_1\"], row[\"Score_2\"], row[\"Score_3\"], row[\"Score_4\"], row[\"Score_5\"], row[\"Score_6\"]]\n",
    "#         # Create the plot\n",
    "#         plt.figure(figsize=(30, 16))\n",
    "#         plt.barh(top_features, feature_scores, align=\"center\", alpha=0.7)\n",
    "#         plt.yticks(fontsize=18)\n",
    "#         plt.xticks(fontsize=18)\n",
    "#         plt.xlabel(\"Feature Importance Score\", fontsize=20)\n",
    "#         plt.ylabel(\"Feature Name\")\n",
    "#         plt.title(f\"Feature Importance Scores for {df_name}\", fontsize=20)\n",
    "#         plt.tight_layout()\n",
    "#         # Save the plot\n",
    "#         plt.savefig(os.path.join(plot_dir, f\"{df_name}_{row['Model']}_feature_importance.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49e64fde10219d3ab96bfbc338b28578e123987725ce81113aeea3e8142c8584"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
